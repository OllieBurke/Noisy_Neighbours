{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import LISA_utils  # This is a python script full of nice tasty functions we can use for LISA (or LIGO) DA\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.constants\n",
    "import os\n",
    "from scipy import integrate\n",
    "plt.rcParams['agg.path.chunksize'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bunch of units\n",
    "\n",
    "GM_sun = 1.3271244*1e20\n",
    "c =2.9979246*1e8\n",
    "M_sun =1.9884099*1e30\n",
    "G = 6.6743*1e-11\n",
    "pc= 3.0856776*1e16\n",
    "pi = np.pi\n",
    "Mpc = 10**6 * pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def htilde_GR(f,eps,params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we calculate a TaylorF2 model up to 2PN which takes as input the following\n",
    "    set of parameters: (log of chirp mass, symmetric mass ratio, beta).\n",
    "    This can easily be changed in the first few lines where the parameters are loaded.\n",
    "    The main reference is https://arxiv.org/pdf/gr-qc/0509116.pdf [Eqs (3.4)].\n",
    "    \n",
    "    Note on distance: \n",
    "    \n",
    "    Notice that the effective distance contains information about the angular dependence\n",
    "    of the binary. The model can thus be used for all detectors, as long as this distance\n",
    "    parameter is chosen consistently. \n",
    "    \n",
    "    Note on spin: \n",
    "    \n",
    "    The spin parameter beta is defined in Eq.(2.3a) in [arxiv:0411129].\n",
    "    Notice that this quantity is constructed in such a way to be smaller or equal\n",
    "    than 9.4, and of course it ranges from 0 (no spins) to this upper value. \n",
    "    The coefficient enters the phase as in Eq.(2.2) in the same paper.\n",
    "    \"\"\"\n",
    "    # Units\n",
    "    \n",
    "    # Load the parameters\n",
    "    Mchirp_true = M_sun * np.exp(params[0])\n",
    "    eta_true = params[1]\n",
    "    beta_true = params[2]\n",
    "    Deff = params[3]\n",
    "    \n",
    "    theta = -11831/9240 #in PN coefficients!\n",
    "    delta = -1987/3080  #in PN coefficients!\n",
    "    # PN expansion parameter (velocity).\n",
    "    \n",
    "    v = (pi*G*Mchirp_true*eta_true**(-3/5)/(c**3) * f)**(1/3)\n",
    "    # Amplitude explicitly given in terms of units and frequency.\n",
    "    # Notice that lowest PN order here is fine. Biggest contributions from phase.\n",
    "    \n",
    "    amplitude_1 = - (Mpc/Deff)*np.sqrt((5/(24*pi)))*(GM_sun/(c**2 *Mpc))\n",
    "    amplitude_2 = (pi*GM_sun/(c**3))**(-1/6) * (Mchirp_true/M_sun)**(5/6)\n",
    "    amplitude = amplitude_1*amplitude_2 * f**(-7/6)\n",
    "    # Phase: add or remove PN orders here as you see fit.\n",
    "    \n",
    "    psi_const = 2*pi*f*t0 - 2*phi0 - pi/4\n",
    "    psi1PN = (3715/756 + (55/9)*eta_true)*v**(-3)\n",
    "    psi1_5PN_tails = -16*pi*v**(-2)\n",
    "    psi1_5PN_spin = 4*beta_true*v**(-2)\n",
    "    \n",
    "    psi2PN = (15293365/508032+(27145/504)*eta_true+(3085/72)*eta_true**2)*v**(-1)\n",
    "    psi25PNlog = pi*(38645/252- (65/3) *eta_true)* np.log(v)\n",
    "    psi3PN = v*(11583231236531/4694215680 - (640/3) * (pi**2) -6848/21 *np.euler_gamma\n",
    "              + eta_true*(-15335597827/3048192 + (2255/12) * (pi**2) - 1760/3 * theta - 12320/9 * delta)\n",
    "              + (eta_true**2) *76055/1728 - (eta_true**3) * 127825/1296 - 6848/21 * np.log(4))\n",
    "    psi3PNlog = - 6848/21 *v * np.log(v)\n",
    "    psi35PN = pi * v**2 * (77096675./254016 + (378515./1512) *eta_true - 74045./756 * (eta_true**2)* (1-eps))\n",
    "    psi_fullPN = (3/(128*eta_true))*(v**(-5)+psi1PN+psi1_5PN_tails+psi1_5PN_spin+psi2PN\n",
    "                                  + psi25PNlog + psi3PN + psi3PNlog + psi35PN)\n",
    "    psi = psi_const + psi_fullPN \n",
    "    return amplitude* np.exp(-1j*psi)\n",
    "\n",
    "def htilde_AP(f,params):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we calculate a TaylorF2 model up to 2PN which takes as input the following\n",
    "    set of parameters: (log of chirp mass, symmetric mass ratio, beta).\n",
    "    This can easily be changed in the first few lines where the parameters are loaded.\n",
    "    The main reference is https://arxiv.org/pdf/gr-qc/0509116.pdf [Eqs (3.4)].\n",
    "    \n",
    "    Note on distance: \n",
    "    \n",
    "    Notice that the effective distance contains information about the angular dependence\n",
    "    of the binary. The model can thus be used for all detectors, as long as this distance\n",
    "    parameter is chosen consistently. \n",
    "    \n",
    "    Note on spin: \n",
    "    \n",
    "    The spin parameter beta is defined in Eq.(2.3a) in [arxiv:0411129].\n",
    "    Notice that this quantity is constructed in such a way to be smaller or equal\n",
    "    than 9.4, and of course it ranges from 0 (no spins) to this upper value. \n",
    "    The coefficient enters the phase as in Eq.(2.2) in the same paper.\n",
    "    \"\"\"\n",
    "    # Units\n",
    "    \n",
    "#     GM_sun = 1.3271244*1e20\n",
    "#     c =2.9979246*1e8\n",
    "#     M_sun =1.9884099*1e30\n",
    "#     G = 6.6743*1e-11\n",
    "#     pc= 3.0856776*1e16\n",
    "#     pi = np.pi\n",
    "#     Mpc = 10**6 * pc\n",
    "    \n",
    "    # Load the parameters\n",
    "    \n",
    "    Mchirp_true = M_sun * np.exp(params[0])\n",
    "    eta_true = params[1]\n",
    "    beta_true = params[2]\n",
    "    Deff = params[3]\n",
    "        \n",
    "    theta = -11831/9240 #in PN coefficients!\n",
    "    delta = -1987/3080  #in PN coefficients!\n",
    "    # PN expansion parameter (velocity).\n",
    "    \n",
    "    v = (pi*G*Mchirp_true*eta_true**(-3/5)/(c**3) * f)**(1/3)\n",
    "    # Amplitude explicitly given in terms of units and frequency.\n",
    "    # Notice that lowest PN order here is fine. Biggest contributions from phase.\n",
    "    \n",
    "    amplitude_1 = - (Mpc/Deff)*np.sqrt((5/(24*pi)))*(GM_sun/(c**2 *Mpc))\n",
    "    amplitude_2 = (pi*GM_sun/(c**3))**(-1/6) * (Mchirp_true/M_sun)**(5/6)\n",
    "    amplitude = amplitude_1*amplitude_2 * f**(-7/6)\n",
    "    # Phase: add or remove PN orders here as you see fit.\n",
    "    \n",
    "    psi_const = 2*pi*f*t0 - 2*phi0 - pi/4\n",
    "    psi1PN = (3715/756+55/9*eta_true)*v**(-3)\n",
    "    psi1_5PN_tails = -16*pi*v**(-2)\n",
    "    psi1_5PN_spin = 4*beta_true*v**(-2)\n",
    "    psi2PN = (15293365/508032+27145/504*eta_true+3085/72*eta_true**2)*v**(-1)\n",
    "    psi25PNlog = pi*(38645/252- 65/3 *eta_true)* np.log(v)\n",
    "    psi3PN = v*(11583231236531/4694215680 -640/3 * pi**2 -6848/21 *np.euler_gamma\n",
    "              + eta_true*(-15335597827/3048192+2255/12 * pi**2-1760/3 * theta - 12320/9 * delta)\n",
    "              + eta_true**2 *76055/1728 - eta_true**3 * 127825/1296 - 6848/21 * np.log(4))\n",
    "    psi3PNlog = - 6848/21 *v * np.log(v)\n",
    "    psi35PN = pi * v**2 * (77096675./254016 + 378515./1512 *eta_true - 74045./756 * eta_true**2)\n",
    "    psi_fullPN = 3/(128*eta_true)*(v**(-5)+psi1PN+psi1_5PN_tails+psi1_5PN_spin+psi2PN\n",
    "                                  + psi25PNlog + psi3PN + psi3PNlog + psi35PN)\n",
    "    psi = psi_const + psi_fullPN \n",
    "    return amplitude* np.exp(-1j*psi)\n",
    "\n",
    "def T_chirp(fmin,M_chirp,eta):\n",
    "\n",
    "    M = (m1 + m2)*M_sun\n",
    "    M_chirp *= M_sun\n",
    "    \n",
    "    M = M_chirp*eta**(-3/5)\n",
    "    v_low = (pi*G*M_chirp*eta**(-3/5)/(c**3) * fmin)**(1/3)\n",
    "    \n",
    "    theta = -11831/9240 #in PN coefficients!\n",
    "    delta = -1987/3080  #in PN coefficients!\n",
    "    gamma = np.euler_gamma\n",
    "    \n",
    "    pre_fact = ((5/(256*eta)) * G*M/(c**3))\n",
    "    first_term = (v_low**(-8) + (743/252 + (11/3) * eta ) * (v_low **(-6)) - (32*np.pi/5)*v_low**(-5)\n",
    "                +(3058673/508032 + (5429/504)*eta + (617/72)*eta**2)*v_low**(-4)\n",
    "                 +(13*eta/3 - 7729/252)*np.pi*v_low**-3)\n",
    "    \n",
    "    second_term = (6848*gamma/105 - 10052469856691/23471078400 + 128*pi**2/3 + (\n",
    "    3147553127/3048192 - 451*(pi**2)/12)*eta - (15211*eta**2)/1728 + (2555*eta**3 / 1296) +\n",
    "                   (6848/105)*np.log(4*v_low))*v_low**-2\n",
    "    \n",
    "    third_term = ((14809/378)*eta**2 - (75703/756) * eta - 15419335/127008)*pi*v_low**-1\n",
    "    return pre_fact * (first_term + second_term + third_term)\n",
    "\n",
    "def final_frequency(M_chirp,eta):\n",
    "    M_tot = M_chirp*eta**(-3/5) * M_sun\n",
    "    \n",
    "    return (c**3)/(6*np.sqrt(6)*np.pi*G*M_tot)\n",
    "    \n",
    "\n",
    "def dh_dlnMc(f,params):\n",
    "    Mchirp= M_sun*np.exp(params[0])\n",
    "    eta=params[1]\n",
    "    beta=params[2]\n",
    "    theta = -11831/9240 #in PN coefficients!\n",
    "    delta = -1987/3080  #in PN coefficients!\n",
    "    v = (pi*G*Mchirp*eta**(-3/5)/(c**3) * f)**(1/3)\n",
    "    C0PN = 5/6+ (5/128) *1j* v**(-5)* eta**(-1)\n",
    "    C1PN = 5*1j*(743+924*eta)/32256 * v**(-3) * eta**(-1)\n",
    "    C1_5PN = -1/16 *1j *(4*pi-beta)* v**-2 * eta**-1\n",
    "    C2PN = 5*1j/65028096 * v**-1 * eta**-1 * (3058673 + 5472432*eta + 4353552 *eta**2)\n",
    "    C2_5PNlog = (65 *1j* pi )/384 - (38645 *1j* pi)/(32256 *eta)\n",
    "    C3PN = (-((76055 *1j* v*eta)/221184) + (127825 *1j* v*eta**2)/165888\n",
    "           + v *((15335597827 *1j)/390168576 - (2255 *1j*pi**2)/1536\n",
    "                 -(385 *1j *delta)/36 + (55 *1j*theta)/12)\n",
    "           + v* eta**-1 * (-((11583231236531 *1j)/600859607040) + (5 *1j*pi**2)/3 \n",
    "                           + (107 *1j*np.euler_gamma)/42 + 107/42 *1j* np.log(4)))\n",
    "    C3PNlog = v* eta**-1 * ((107 *1j)/42 + 107/42 *1j *np.log(v)) \n",
    "    C3_5PN = (-((378515 *1j *pi* v**2)/96768) \n",
    "              - (77096675 *1j *pi* v**2)/(16257024 *eta) \n",
    "              + (74045 *1j *pi * v**2 *eta)/48384)\n",
    "    return (C0PN + C1PN + C1_5PN+ C2PN + C2_5PNlog+C3PN + C3PNlog + C3_5PN)*htilde_AP(f,params)\n",
    "def dh_deta(f,params):\n",
    "    Mchirp= M_sun* np.exp(params[0])\n",
    "    eta=params[1]\n",
    "    beta=params[2]\n",
    "    theta = -11831/9240 #in PN coefficients!\n",
    "    delta = -1987/3080  #in PN coefficients!\n",
    "    v = (pi*G*Mchirp*eta**(-3/5)/(c**3) * f)**(1/3)\n",
    "    C1PN = 743*1j/16128 * v**-3 * eta**-2 - 11*1j/128 * v**-3* eta**-1\n",
    "    C1_5PN = -9*1j*pi/40* v**-2 * eta**-2 +9*1j*beta/160 * v**-2 * eta**-2\n",
    "    C2PN =  1j* v**-1 *( -617/512 - 5429/21504*eta**-1 + 3058673/5419008* eta**-2)\n",
    "    C2_5PNlog = (-13 *1j *pi/(128 * eta) + ((7729 *1j *pi)/10752 \n",
    "                    + (38645 *1j *pi * np.log(v))/10752)/(eta**2))\n",
    "    C3PN = (-((15211 *1j* v)/18432) + (25565 *1j* v *eta)/6144 \n",
    "            + (v* (-((15335597827 *1j)/650280960) + (451 *1j*pi**2)/512 + (77 *1j*delta)/12 \n",
    "                  - (11 *1j*theta)/4))/eta + (v * ((11583231236531 *1j)/166905446400 \n",
    "                                                     - 6 *1j*pi**2 - (321 *1j*np.euler_gamma)/35 \n",
    "                                                     - 321/35 *1j*np.log(4)))/(eta**2))\n",
    "    C3PNlog = (v *(-((107 *1j)/70) - 321/35 *1j*np.log(v)))/(eta**2)\n",
    "    C3_5PN = ((14809 *1j*pi*v**2 )/10752 \n",
    "              + (15419335 *1j*pi*v**2)/(1548288* eta**2) \n",
    "              + (75703 *1j*pi*v**2)/(32256 *eta))\n",
    "    return (C1PN + C1_5PN + C2PN + C2_5PNlog + C3PN  + C3PNlog + C3_5PN)*htilde_AP(f,params)\n",
    "\n",
    "def dh_dbeta(f,params):\n",
    "    Mchirp= M_sun * np.exp(params[0])\n",
    "    eta=params[1]\n",
    "    beta=params[2]\n",
    "    v = (pi*G*Mchirp*eta**(-3/5)/(c**3) * f)**(1/3)\n",
    "    C1_5PN = -3/32 *1j* v**(-2)*eta**-1\n",
    "    return (C1_5PN)*htilde_AP(f,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ET_PSD(f):\n",
    "    \"\"\"\n",
    "    Analytical fit: https://arxiv.org/pdf/1201.3563.pdf\n",
    "    \"\"\"\n",
    "    x = f/100\n",
    "\n",
    "    hn_sqr = (2.39 * 1e-27 * x**(-15.64) + 0.349 * x**(-2.145) + 1.76 * x**-0.12 + 0.409 * x**(1.10))**2\n",
    "    \n",
    "    return 1e-50 * hn_sqr\n",
    "\n",
    "def inner_prod(sig1_f,sig2_f,PSD,delta_f):\n",
    "    \"\"\"\n",
    "    Wiener Product with constant PSD. Here we use Parseval's theorem. Note the definition of the SNR.\n",
    "    \"\"\"\n",
    "    return (4*delta_f)  * np.real(sum(sig1_f*np.conjugate(sig2_f)/PSD))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnostics for source 1\n",
      "Final frequency [Hz] for source 1 54.964684798034675\n",
      "chirping time [minutes]  0.42286068695858614\n",
      "\n",
      "Diagnostics for source 2\n",
      "Final frequency [Hz] for source 2 62.81678262632534\n",
      "chirping time [minutes]  0.6076815025468655\n",
      "\n",
      "SNR for source 1 1292.4206958990737\n",
      "SNR for source 2 10790.053520194175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_params = 3\n",
    "N_resolved = 2\n",
    "\n",
    "# Fix these two impostors, assume they are known perfectly.\n",
    "\n",
    "fmin = 5\n",
    "\n",
    "\n",
    "# Set up true parameters: SOURCE 1\n",
    "\n",
    "Deff_1 = 400 * Mpc\n",
    "beta_1 = 1\n",
    "m1 = 30  \n",
    "m2 = 50\n",
    "M_tot_1 = (m1 + m2)  # M total  [dimensionless]\n",
    "eta_1 = (m1*m2)/(M_tot_1**2)  # Symmetric mass ratio [dimensionless]=\n",
    "M_chirp_1 = M_tot_1*eta_1**(3/5)  # Chirp mass in units of kilograms \n",
    "\n",
    "f_max_1 = final_frequency(M_chirp_1,eta_1)  # Calculate maximum frequency (Schwarzschild ISCO frequency)\n",
    "t_max_1 = T_chirp(fmin,M_chirp_1,eta_1)     # Calculate maximum chirping time that binary radiates stuff\n",
    "\n",
    "print(\"Diagnostics for source 1\")\n",
    "\n",
    "print('Final frequency [Hz] for source 1',final_frequency(M_chirp_1,eta_1))\n",
    "print('chirping time [minutes] ',t_max_1/60)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Set up true parameters: SOURCE 2\n",
    "\n",
    "Deff_2 = 40 * Mpc\n",
    "beta_2 = 5\n",
    "m1 = 20  \n",
    "m2 = 50\n",
    "M_tot_2 = (m1 + m2)  # M total  [dimensionless]\n",
    "eta_2 = (m1*m2)/(M_tot_2**2)  # Symmetric mass ratio [dimensionless]=\n",
    "M_chirp_2 = M_tot_2*eta_2**(3/5)  # Chirp mass [dimensionless]\n",
    "\n",
    "f_max_2 = final_frequency(M_chirp_2,eta_2)   # Calculate maximum frequency (Schwarzschild ISCO frequency)\n",
    "t_max_2 = T_chirp(fmin,M_chirp_2,eta_2)      # Calcuilate maximum chirping time that binary radiates stuff\n",
    "\n",
    "print(\"Diagnostics for source 2\")\n",
    "\n",
    "print('Final frequency [Hz] for source 2',final_frequency(M_chirp_2,eta_2))\n",
    "print('chirping time [minutes] ',t_max_2/60)\n",
    "\n",
    "# Calculate max frequency and chirp time\n",
    "\n",
    "fmax = max(f_max_1,f_max_2)  # Compute max frequency\n",
    "fmax_min_sources = min(f_max_1,f_max_2)  # Compute \"smallest\" largest frequency\n",
    "\n",
    "tmax = max(t_max_1,t_max_2)  # Compute maximum chirping time for both binaries\n",
    "tmin = min(t_max_1,t_max_2)  # Compute minimum chirping time for both binaries\n",
    "\n",
    "t0 = tmin\n",
    "phi0 = 0.\n",
    "\n",
    "delta_t = 1/(2*fmax)         # Set sampling interval so that we can resolved frequencies of BOTH signals\n",
    "\n",
    "t = np.arange(0,tmax,delta_t)     # Set up useless time vector\n",
    "n_t = len(t)                      # Extract length\n",
    "\n",
    "delta_f = 1/(n_t*delta_t)         # Extract sampling frequency\n",
    "\n",
    "freq_bin = np.arange(fmin,fmax_min_sources,delta_f)     # Extract frequency series\n",
    "n_f = len(freq_bin)                         # Extract length of frequency domain series\n",
    "\n",
    "\n",
    "logMchirp_1 = np.log(M_chirp_1)\n",
    "logMchirp_2 = np.log(M_chirp_2)\n",
    "\n",
    "pars_1 = [logMchirp_1,eta_1,beta_1,Deff_1] # array of parameters for waveform.\n",
    "pars_2 = [logMchirp_2,eta_2,beta_2,Deff_2] # array of parameters for waveform.\n",
    "\n",
    "eps_GR = 2*1e-2         # Input waveform errors into the TRUE signal. This is for convenience (don't have to)\n",
    "                        # fuck around with the derivatives\n",
    "\n",
    "\n",
    "h_f_1 = htilde_GR(freq_bin,eps_GR,pars_1)    # Extract signal 1 in frequency domain\n",
    "h_f_2 = htilde_GR(freq_bin,eps_GR,pars_2)    # Extract signal 2 in frequency domain\n",
    "\n",
    "# h_f_approx = htilde_AP(freq_bin,pars)\n",
    "\n",
    "\n",
    "# SNR\n",
    "\n",
    "PSD = ET_PSD(freq_bin)        # Extract PSD fit to ET evaluated at frequencies defined above\n",
    " \n",
    "SNR2_1 = inner_prod(h_f_1,h_f_1,PSD,delta_f)\n",
    "SNR2_2 = inner_prod(h_f_2,h_f_2,PSD,delta_f)   # Compute SNR\n",
    "\n",
    "print(\"\")\n",
    "print('SNR for source 1',np.sqrt(SNR2_1))\n",
    "print('SNR for source 2',np.sqrt(SNR2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_unres = 4    # 4 unoticed binaries\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "unres_m1 = abs(np.random.normal(1.4,2,N_unres)) \n",
    "unres_m2 = abs(np.random.uniform(1.4,2,N_unres))              # Generate randomly spaced source parameters\n",
    "D_unres = abs(np.random.uniform(200*Mpc,400*Mpc,N_unres))   \n",
    "\n",
    "unres_M_tot = [(unres_m1[i] + unres_m2[i]) for i in range(N_unres)]   # Compute M_tot for each source\n",
    "\n",
    "# Compute M_chirp for each source\n",
    "unres_M_chirp = [(unres_m1[i]*unres_m2[i])**(3/5)/(unres_m1[i] + unres_m2[i])**(1/5) for i in range(N_unres)]\\\n",
    "\n",
    "# Compute eta for each source\n",
    "unres_eta = [(unres_M_tot[i] * unres_M_chirp[i])**(5/3) for i in range(N_unres)]\n",
    "# Compute beta for each source\n",
    "unres_beta = abs(np.random.normal(5,1,N_unres))\n",
    "\n",
    "# Compute list of unnoticed sources\n",
    "unres_signal_f = [htilde_GR(freq_bin,eps_GR,[unres_M_chirp[i],unres_eta[i],unres_beta[i],D_unres[i]]) for i in range(0,N_unres)]\n",
    "\n",
    "# Compute squared SNR of each source\n",
    "SNR2 = [inner_prod(unres_signal_f[i],unres_signal_f[i],PSD,delta_f) for i in range(0,N_unres)]\n",
    "\n",
    "# Compute sum of unnoticed signals in the frequency domain\n",
    "sum_unres_signal_f = sum(unres_signal_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.sqrt(SNR2),'*')\n",
    "plt.xlabel('signal',fontsize = 20)\n",
    "plt.ylabel(r'$\\rho$')\n",
    "plt.title('SNR of unnoticed binaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numerical Derivatives - Source 1\n",
    "\n",
    "# Chirp mass\n",
    "logMchirp_delta = 1e-6\n",
    "params_1_p = [logMchirp_1 + logMchirp_delta,eta_1,beta_1,Deff_1]\n",
    "params_1_m = [logMchirp_1 - logMchirp_delta,eta_1,beta_1,Deff_1]\n",
    "\n",
    "deriv_log_Mchirp_1 = (htilde_AP(freq_bin,params_1_p) - htilde_AP(freq_bin,params_1_m))/(2*logMchirp_delta)\n",
    "\n",
    "# eta\n",
    "eta_delta = 1e-6\n",
    "params_1_p = [logMchirp_1,eta_1 + eta_delta,beta_1,Deff_1]\n",
    "params_1_m = [logMchirp_1,eta_1 - eta_delta,beta_1,Deff_1]\n",
    "\n",
    "deriv_log_eta_1 = (htilde_AP(freq_bin,params_1_p) - htilde_AP(freq_bin,params_1_m))/(2*eta_delta)\n",
    "\n",
    "# beta\n",
    "beta_delta = 1e-6\n",
    "params_1_p = [logMchirp_1,eta_1,beta_1 + beta_delta,Deff_1]\n",
    "params_1_m = [logMchirp_1,eta_1,beta_1 - beta_delta,Deff_1]\n",
    "\n",
    "deriv_log_beta_1 = (htilde_AP(freq_bin,params_1_p) - htilde_AP(freq_bin,params_1_m))/(2*beta_delta)\n",
    "\n",
    "# Numerical Derivatives - Source 2\n",
    "\n",
    "# Chirp mass\n",
    "logMchirp_delta = 1e-6\n",
    "params_2_p = [logMchirp_2 + logMchirp_delta,eta_2,beta_2,Deff_2]\n",
    "params_2_m = [logMchirp_2 - logMchirp_delta,eta_2,beta_2,Deff_2]\n",
    "\n",
    "deriv_log_Mchirp_2 = (htilde_AP(freq_bin,params_2_p) - htilde_AP(freq_bin,params_2_m))/(2*logMchirp_delta)\n",
    "\n",
    "# eta \n",
    "eta_delta = 1e-6\n",
    "params_2_p = [logMchirp_2,eta_2 + eta_delta,beta_2,Deff_2]\n",
    "params_2_m = [logMchirp_2,eta_2 - eta_delta,beta_2,Deff_2]\n",
    "\n",
    "deriv_log_eta_2 = (htilde_AP(freq_bin,params_2_p) - htilde_AP(freq_bin,params_2_m))/(2*eta_delta)\n",
    "\n",
    "# beta\n",
    "beta_delta = 1e-6\n",
    "params_2_p = [logMchirp_2,eta_2,beta_2 + beta_delta,Deff_2]\n",
    "params_2_m = [logMchirp_2,eta_2,beta_2 - beta_delta,Deff_2]\n",
    "\n",
    "deriv_log_beta_2 = (htilde_AP(freq_bin,params_2_p) - htilde_AP(freq_bin,params_2_m))/(2*beta_delta)\n",
    "\n",
    "diff_vec = [deriv_log_Mchirp_1,deriv_log_eta_1,deriv_log_beta_1,\n",
    "            deriv_log_Mchirp_2,deriv_log_eta_2,deriv_log_beta_2]\n",
    "\n",
    "\n",
    "fish_mix = np.eye(N_resolved * N_params)\n",
    "for i in range(0,N_resolved * N_params):\n",
    "    for j in range(0,N_resolved * N_params):\n",
    "        fish_mix[i,j] = inner_prod(diff_vec[i],diff_vec[j],PSD,delta_f)\n",
    "        \n",
    "        \n",
    "\n",
    "import mpmath as mp\n",
    "mp.dps = 4000;  \n",
    "\n",
    "fish_mix_prec = mp.matrix(fish_mix)\n",
    "\n",
    "fish_mix_inv = fish_mix_prec**-1\n",
    "\n",
    "Cov_Matrix = np.eye(N_resolved * N_params)\n",
    "for i in range(0,N_resolved * N_params):\n",
    "    for j in range(0,N_resolved * N_params):\n",
    "        Cov_Matrix[i,j] = float(fish_mix_inv[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.diag(Cov_Matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MCMC\n",
    "\n",
    "# MCMC\n",
    "\"\"\"\n",
    "Created on Mon Nov 25 23:53:26 2019\n",
    "\n",
    "@author: Ollie\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def llike(pdgrm, variances):\n",
    "    \"\"\"\n",
    "    Computes log (Whittle) likelihood \n",
    "    \"\"\"\n",
    "\n",
    "    return -0.5 * sum(pdgrm / variances)\n",
    "\n",
    "def lprior_logM_chirp(logM_chirp,logM_chirp_low, logM_chirp_high):\n",
    "    \"\"\"\n",
    "    Prior on amplitude - uniform\n",
    "    \"\"\"\n",
    "\n",
    "    if logM_chirp < logM_chirp_low or logM_chirp > logM_chirp_high:\n",
    "        print('rejected logM_chirp')\n",
    "        return -1e100\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def lprior_eta(eta,eta_low, eta_high):\n",
    "    \"\"\"\n",
    "    Prior on amplitude - uniform\n",
    "    \"\"\"\n",
    "    if eta < eta_low or eta > eta_high:\n",
    "        print('rejected eta')\n",
    "\n",
    "        return -1e100\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def lprior_beta(beta,beta_low, beta_high):\n",
    "    \"\"\"\n",
    "    Prior on amplitude - uniform\n",
    "    \"\"\"\n",
    "\n",
    "    if beta < beta_low or beta > beta_high:\n",
    "        print('rejected beta')\n",
    "        return -1e100\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def lpost(pdgrm, variances,\n",
    "          logM_chirp_1,logM_chirp_2, logM_chirp_low,logM_chirp_high,\n",
    "          eta_1, eta_2, eta_low, eta_high,\n",
    "          beta_1, beta_2, beta_low, beta_high):\n",
    "    '''\n",
    "    Compute log posterior\n",
    "    '''\n",
    "    \n",
    "    return(lprior_logM_chirp(logM_chirp_1,logM_chirp_low, logM_chirp_high) +\n",
    "           lprior_logM_chirp(logM_chirp_2,logM_chirp_low, logM_chirp_high) +\n",
    "           lprior_eta(eta_1,eta_low, eta_high) + \n",
    "           lprior_eta(eta_2,eta_low, eta_high) +\n",
    "           lprior_beta(beta_1,beta_low, beta_high) +\n",
    "           lprior_beta(beta_2,beta_low, beta_high) +\n",
    "           + llike(pdgrm, variances))\n",
    "\n",
    "\n",
    "def accept_reject(lp_prop, lp_prev):\n",
    "    '''\n",
    "    Compute log acceptance probability (minimum of 0 and log acceptance rate)\n",
    "    Decide whether to accept (1) or reject (0)\n",
    "    '''\n",
    "    u = np.random.uniform(size = 1)  # U[0, 1]\n",
    "    r = np.minimum(0, lp_prop - lp_prev)  # log acceptance probability\n",
    "    if np.log(u) < r:\n",
    "        return(1)  # Accept\n",
    "    else:\n",
    "        return(0)  # Reject\n",
    "    \n",
    " \n",
    "\n",
    "def accept_rate(parameter):\n",
    "    '''\n",
    "    Compute acceptance rate for a specific parameter\n",
    "    Used to adapt the proposal variance in a MH sampler\n",
    "    Input: parameter (sequence of samples of a parameter)\n",
    "    '''\n",
    "    rejections = 0\n",
    "    for i in range(len(parameter) - 1):  # Count rejections\n",
    "        rejections = rejections + (parameter[i + 1] == parameter[i])\n",
    "    reject_rate = rejections / (len(parameter) - 1)  # Rejection rate\n",
    "    return(1 - reject_rate)  # Return acceptance rate\n",
    "    \n",
    "\n",
    "#####\n",
    "#####\n",
    "    \n",
    "\n",
    "def MCMC_full(data_f,f, true_vals,D_vec,Cov_Matrix,\n",
    "                          Variances,\n",
    "                           M_chirp_high,M_chirp_low,\n",
    "                           eta_high, eta_low,\n",
    "                           beta_high, beta_low,\n",
    "                           Ntotal, \n",
    "                           burnin, \n",
    "                           printerval = 50):\n",
    "\n",
    "    \n",
    "    np.random.seed(2) # Set the seed\n",
    "    \n",
    "    \n",
    "    logM_chirp_1 = []   # Initialise empty vectors\n",
    "    eta_1 = []\n",
    "    beta_1 = []\n",
    "    Deff_1 = []\n",
    "    \n",
    "    logM_chirp_2 = []   # Initialise empty vectors\n",
    "    eta_2 = []\n",
    "    beta_2 = []\n",
    "    Deff_2 = []\n",
    "      \n",
    "\n",
    "    logM_chirp_1.append(true_vals[0])\n",
    "    eta_1.append(true_vals[1])\n",
    "    beta_1.append(true_vals[2])\n",
    "    Deff_1.append(D_vec[0])\n",
    "    \n",
    "    logM_chirp_2.append(true_vals[3])\n",
    "    eta_2.append(true_vals[4])\n",
    "    beta_2.append(true_vals[5])\n",
    "    Deff_2.append(D_vec[1])\n",
    "    \n",
    "    delta_f = f[1] - f[0]   # Extract sampling interval\n",
    "    \n",
    "    params_1 = [logM_chirp_1[0],eta_1[0],beta_1[0],Deff_1[0]]\n",
    "    params_2 = [logM_chirp_2[0],eta_2[0],beta_2[0],Deff_2[0]]\n",
    "    \n",
    "    signal_init_f_1 = htilde_AP(f,params_1)\n",
    "    signal_init_f_2 = htilde_AP(f,params_2)\n",
    "    \n",
    "    signal_f_init_tot = signal_init_f_1 + signal_init_f_2 \n",
    "\n",
    "    # Compute periodogram\n",
    "    pdgrm = abs(data_f - signal_f_init_tot)**2  \n",
    "    print('pdgrm is',pdgrm)\n",
    "                                                      \n",
    "    # Initial value for log posterior\n",
    "    lp = []\n",
    "    lp.append(lpost(pdgrm, variances,\n",
    "                    logM_chirp_1[0], logM_chirp_2[0], logM_chirp_low, logM_chirp_high,\n",
    "                    eta_1[0], eta_2[0], eta_low, eta_high,\n",
    "                    beta_1[0], beta_2[0], beta_low, beta_high))\n",
    "    \n",
    "    lp_store = lp[0]  # Create log posterior storage to be overwritten\n",
    "\n",
    "    accept_reject_count = [0]   \n",
    "    #####                                                  \n",
    "    # Run MCMC\n",
    "    #####\n",
    "    for i in range(1, Ntotal):\n",
    "\n",
    "        if i % printerval == 0:\n",
    "            print(\"i = \", i)  # Iteration and Acceptance/Rejection ratio \n",
    "            print(\"acceptance_reject ratio\", 100*sum(accept_reject_count)/len(accept_reject_count),'percent')\n",
    "            \n",
    "\n",
    "        ####\n",
    "\n",
    "        #####\n",
    "        # Step 1: Sample spin, a\n",
    "        #####\n",
    "        \n",
    "        lp_prev = lp_store  # Call previous stored log posterior\n",
    "        \n",
    "\n",
    "        prev_vec = [logM_chirp_1[i - 1], eta_1[i - 1], beta_1[i - 1],\n",
    "                   logM_chirp_2[i - 1], eta_2[i - 1], beta_2[i - 1]]\n",
    "    \n",
    "        \n",
    "        \n",
    "        prop_vec = np.random.multivariate_normal(prev_vec, (1/2)*Cov_Matrix)\n",
    "        \n",
    "\n",
    "        logM_chirp_prop_1 = prop_vec[0]\n",
    "        eta_prop_1 = prop_vec[1]\n",
    "        beta_prop_1 = prop_vec[2]\n",
    "        \n",
    "        logM_chirp_prop_2 = prop_vec[3]\n",
    "        eta_prop_2 = prop_vec[4]\n",
    "        beta_prop_2 = prop_vec[5]\n",
    "\n",
    "        \n",
    "        param_1_prop = [logM_chirp_prop_1, eta_prop_1, beta_prop_1, Deff_1[0]]\n",
    "        param_2_prop = [logM_chirp_prop_2, eta_prop_2, beta_prop_2, Deff_2[0]]\n",
    "        \n",
    "        signal_prop_f_1  = htilde_AP(f,param_1_prop)  # New proposed signal\n",
    "        signal_prop_f_2  = htilde_AP(f,param_2_prop)  # New proposed signal\n",
    "        \n",
    "        signal_prop_f_tot = signal_prop_f_1 + signal_prop_f_2\n",
    "        \n",
    "        pdgrm_prop = abs(data_f - signal_prop_f_tot)**2  # Compute periodigram\n",
    "        \n",
    "        \n",
    "        # Compute log posterior\n",
    "        lp_prop = lpost(pdgrm_prop, variances, \n",
    "                         logM_chirp_prop_1,logM_chirp_prop_2,logM_chirp_low,logM_chirp_high,\n",
    "                           eta_prop_1,eta_prop_2, eta_low, eta_high,\n",
    "                             beta_prop_1, beta_prop_2, beta_low, beta_high)  # Compute proposed log posterior\n",
    "        \n",
    "\n",
    "        if accept_reject(lp_prop, lp_prev) == 1:  # Accept\n",
    "            logM_chirp_1.append(logM_chirp_prop_1) \n",
    "            eta_1.append(eta_prop_1)\n",
    "            beta_1.append(beta_prop_1)\n",
    "\n",
    "            logM_chirp_2.append(logM_chirp_prop_2) \n",
    "            eta_2.append(eta_prop_2)\n",
    "            beta_2.append(beta_prop_2)\n",
    "            \n",
    "            accept_reject_count.append(1)  # Add one to counter\n",
    "              \n",
    "            lp_store = lp_prop  # Overwrite lp_store\n",
    "\n",
    "        else:  # Reject\n",
    "            \n",
    "            logM_chirp_1.append(logM_chirp_1[i - 1]) \n",
    "            eta_1.append(eta_1[i - 1])\n",
    "            beta_1.append(beta_1[i - 1])\n",
    "\n",
    "            logM_chirp_2.append(logM_chirp_2[i - 1]) \n",
    "            eta_2.append(eta_2[i - 1])\n",
    "            beta_2.append(beta_2[i - 1])\n",
    "            \n",
    "            accept_reject_count.append(0)  # Add 0 to counter\n",
    "              \n",
    "        lp.append(lp_store)  # Add log posterior value\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    return logM_chirp_1,eta_1,beta_1,logM_chirp_2,eta_2,beta_2,lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variances = (PSD)/(4*delta_f)   # Variances (denominator of likelihood)\n",
    "np.random.seed(2)\n",
    "noise_real = np.random.normal(0,np.sqrt(variances))\n",
    "noise_imag = np.random.normal(0,np.sqrt(variances))\n",
    "\n",
    "noise_f = noise_real + 1j*noise_imag\n",
    "\n",
    "data_f = h_f_1 + h_f_2 + sum_unres_signal_f + noise_f\n",
    "\n",
    "\n",
    "\n",
    "Ntotal = 100000  # Number of iterations\n",
    "burnin = 0\n",
    "\n",
    "logM_chirp_low = -100   # a prior bound (high)\n",
    "logM_chirp_high = np.log(200)     # a prior bound (low)\n",
    "\n",
    "eta_low = 0\n",
    "eta_high = 0.25\n",
    "\n",
    "beta_low = 0\n",
    "beta_high = 9.4\n",
    "\n",
    "\n",
    "true_vals = [np.log(M_chirp_1),eta_1,beta_1,\n",
    "            np.log(M_chirp_2),eta_2,beta_2]\n",
    "\n",
    "D_vec = [Deff_1,Deff_2]\n",
    "\n",
    "# Run the algorithm\n",
    "logM_chirp_1_samps,eta_1_samps,beta_1_samps,logM_chirp_2_samps,eta_2_samps,beta_2_samps,lp = MCMC_full(data_f,\n",
    "                                                   freq_bin, true_vals,D_vec,Cov_Matrix,\n",
    "                                                   variances,\n",
    "                                                   logM_chirp_high,logM_chirp_low,\n",
    "                                                   eta_high,eta_low,\n",
    "                                                   beta_high,beta_low,\n",
    "                                                   Ntotal, \n",
    "                                                   burnin, \n",
    "                                                   printerval = 2000,\n",
    "                                                   )\n",
    "\n",
    "\n",
    "# logM_chirp_samps = logM_chirp_samps[burnin:]\n",
    "# eta_samps = eta_samps[burnin:]\n",
    "# beta_samps = beta_samps[burnin:]\n",
    "# lp = lp[burnin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# burnin = 5000\n",
    "\n",
    "# logM_chirp_1_samps = logM_chirp_1_samps[burnin:]\n",
    "# eta_1_samps = eta_1_samps[burnin:]\n",
    "# beta_1_samps = beta_1_samps[burnin:]\n",
    "\n",
    "# logM_chirp_2_samps = logM_chirp_2_samps[burnin:]\n",
    "# eta_2_samps = eta_2_samps[burnin:]\n",
    "# beta_2_samps = beta_2_samps[burnin:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('MCMC logM_chirp:',np.sqrt(np.var(logM_chirp_1_samps)))\n",
    "print('MCMC eta:',np.sqrt(np.var(eta_1_samps)))\n",
    "print('MCMC beta:',np.sqrt(np.var(beta_1_samps)))\n",
    "\n",
    "print('FM:',np.sqrt(np.diag(Cov_Matrix)[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize = (20,5))\n",
    "\n",
    "ax[0].hist(logM_chirp_1_samps,bins = 30,label = 'Posterior')\n",
    "ax[0].axvline(x = np.log(M_chirp_1),c = 'red', label = 'True Value')\n",
    "# ax[0].axvline(x = a_res + a_bias, color = 'g', label = 'Predicted bias')\n",
    "ax[0].set_xlabel(r'$\\log \\mathcal{M}_{c}$',fontsize = 16)\n",
    "ax[0].set_ylabel(r'$P(\\log \\mathcal{M}_{c}|d,\\eta,\\beta)$',fontsize = 16)\n",
    "ax[0].set_title(r'Log Chirp Mass - $\\log \\mathcal{M}_{c}$',fontsize = 16)\n",
    "# plt.xlim([1.794,1.803])\n",
    "ax[0].locator_params(axis='x', nbins=5)\n",
    "ax[0].legend()\n",
    "# ax[0].show()\n",
    "\n",
    "\n",
    "\n",
    "ax[1].hist(eta_1_samps,bins = 30,label = 'Posterior')\n",
    "ax[1].axvline(x = eta_1,c = 'red', label = 'True Value')\n",
    "# ax[1].axvline(x = f_res + f0_bias, color = 'g', label = 'Predicted bias')\n",
    "ax[1].set_xlabel(r'$\\eta$',fontsize = 16)\n",
    "ax[1].set_ylabel(r'$P(\\eta|d,\\log \\mathcal{M}_{c},\\beta)$',fontsize = 16)\n",
    "ax[1].set_title(r'Symmetric Mass Ratio - $\\eta$',fontsize = 16)\n",
    "# plt.xlim([1.794,1.803])\n",
    "ax[1].legend()\n",
    "# ax[1].show()\n",
    "\n",
    "\n",
    "ax[2].hist(beta_1_samps,bins = 30,label = 'Posterior')\n",
    "ax[2].axvline(x = beta_1,c = 'red', label = 'True Value')\n",
    "# ax[2].axvline(x = phi_res + phi_bias,c = 'g',label = 'Predicted bias' )\n",
    "ax[2].set_xlabel(r'$\\beta$',fontsize = 16)\n",
    "ax[2].set_ylabel(r'$P(\\beta|d,\\log \\mathcal{M}_{c},\\eta)$',fontsize = 16)\n",
    "ax[2].set_title(r'PN spin param - $\\beta$',fontsize = 16)\n",
    "ax[2].legend()\n",
    "# ax[2].show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FM formalism\n",
    "\n",
    "deltaH = sum_unres_signal_f\n",
    "\n",
    "waveform_errors = (htilde_GR(freq_bin,eps_GR,pars_1) - htilde_AP(freq_bin,pars_1) + \n",
    "                   htilde_GR(freq_bin,eps_GR,pars_2) - htilde_AP(freq_bin,pars_2))\n",
    "\n",
    "\n",
    "deltah = waveform_errors + deltaH + noise_f\n",
    "\n",
    "b_vec_n = [inner_prod(diff_vec[i],noise_f,PSD,delta_f) for i in range(0,6)]\n",
    "b_vec_waveform_errors = [inner_prod(diff_vec[i],waveform_errors,PSD,delta_f) for i in range(0,6)]\n",
    "b_vec_unresolved_signals = [inner_prod(diff_vec[i],deltaH,PSD,delta_f) for i in range(0,6)]\n",
    "\n",
    "\n",
    "biases_pred_n = np.matmul(Cov_Matrix,b_vec_n)\n",
    "biases_pred_waveform_errors = np.matmul(Cov_Matrix,b_vec_waveform_errors)\n",
    "biases_pred_unresolved = np.matmul(Cov_Matrix,b_vec_unresolved_signals)\n",
    "\n",
    "biases_pred_unresolved_total = biases_pred_n + biases_pred_waveform_errors + biases_pred_unresolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_chirp_bias_1 = biases_pred_unresolved_total[0]\n",
    "eta_bias_1 = biases_pred_unresolved_total[1]\n",
    "beta_bias_1 = biases_pred_unresolved_total[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize = (20,6))\n",
    "\n",
    "ax[0].hist(logM_chirp_1_samps,bins = 30,color = 'black', histtype = 'stepfilled', alpha = 0.3)\n",
    "ax[0].axvline(x = np.log(M_chirp_1),c = 'red', label = 'True Value')\n",
    "ax[0].axvline(x = np.log(M_chirp_1) + M_chirp_bias_1, color = 'orange', label = 'Predicted bias')\n",
    "ax[0].axvline(x = np.log(M_chirp_1) + biases_pred_n[0],c = 'black',label = 'Noise bias' )\n",
    "ax[0].axvline(x = np.log(M_chirp_1) + biases_pred_waveform_errors[0],c = 'blue',label = 'Waveform bias' )\n",
    "ax[0].axvline(x = np.log(M_chirp_1) + biases_pred_unresolved[0],c = 'green',label = 'Missing  signal bias' )\n",
    "ax[0].set_xlabel(r'$\\log \\mathcal{M}^{(1)}_{c}$',fontsize = 16)\n",
    "ax[0].set_ylabel(r'$P(\\log \\mathcal{M}^{(1)}_{c}|d,\\eta^{(1)},\\beta^{(1)},\\boldsymbol{\\theta}^{(2)})$',fontsize = 16)\n",
    "ax[0].set_title(r'Log Chirp Mass - $\\log \\mathcal{M}^{(1)}_{c}$',fontsize = 16)\n",
    "# plt.xlim([1.794,1.803])\n",
    "ax[0].locator_params(axis='x', nbins=5)\n",
    "# ax[0].legend()\n",
    "# ax[0].show()\n",
    "\n",
    "\n",
    "\n",
    "ax[1].hist(eta_1_samps,bins = 30,color = 'black', histtype = 'stepfilled', alpha = 0.3)\n",
    "ax[1].axvline(x = eta_1,c = 'red', label = 'True Value')\n",
    "ax[1].axvline(x = eta_1 + eta_bias_1, color = 'orange', label = 'Predicted bias')\n",
    "ax[1].axvline(x = eta_1 + biases_pred_n[1],c = 'black',label = 'Noise bias' )\n",
    "ax[1].axvline(x = eta_1 + biases_pred_waveform_errors[1],c = 'blue',label = 'Waveform bias' )\n",
    "ax[1].axvline(x = eta_1 + biases_pred_unresolved[1],c = 'green',label = 'Missing signal bias' )\n",
    "ax[1].set_xlabel(r'$\\eta^{(1)}$',fontsize = 16)\n",
    "ax[1].set_ylabel(r'$P(\\eta^{(1)}|d,\\log \\mathcal{M}^{(1)}_{c},\\beta^{(1)},\\boldsymbol{\\theta}^{(2)})$',fontsize = 16)\n",
    "ax[1].set_title(r'Symmetric Mass Ratio - $\\eta^{(1)}$',fontsize = 16)\n",
    "# plt.xlim([1.794,1.803])\n",
    "# ax[1].legend()\n",
    "# ax[1].show()\n",
    "\n",
    "\n",
    "ax[2].hist(beta_1_samps,bins = 30,color = 'black', histtype = 'stepfilled', alpha = 0.3)\n",
    "ax[2].axvline(x = beta_1,c = 'red', label = 'True Value')\n",
    "ax[2].axvline(x = beta_1 + beta_bias_1,c = 'orange',label = 'Predicted bias' )\n",
    "ax[2].axvline(x = beta_1 + biases_pred_n[2],c = 'black',label = 'Noise bias' )\n",
    "ax[2].axvline(x = beta_1 + biases_pred_waveform_errors[2],c = 'blue',label = 'Waveform bias' )\n",
    "ax[2].axvline(x = beta_1 + biases_pred_unresolved[2],c = 'green',label = 'Missing signal bias' )\n",
    "ax[2].set_xlabel(r'$\\beta^{(1)}$',fontsize = 16)\n",
    "ax[2].set_ylabel(r'$P(\\beta^{(1)}|d,\\log \\mathcal{M}^{(1)}_{c},\\eta^{(1)},\\boldsymbol{\\theta}^{(2)})$',fontsize = 16)\n",
    "ax[2].set_title(r'PN spin param - $\\beta^{(1)}$',fontsize = 16)\n",
    "# ax[2].legend()\n",
    "# ax[2].show()\n",
    "plt.tight_layout()\n",
    "box = ax[1].get_position()\n",
    "# ax[1].set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "#                  box.width, box.height * 0.9])\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax[1].legend(fontsize = 20, loc='upper center', bbox_to_anchor=(0.5, -0.20),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.27)\n",
    "\n",
    "os.chdir('/Users/Ollie/Documents/GitHub_Repositories/population-systematics/Codes/OB/GW_Sources/TaylorF2_Examples/LIGO_case/plots')\n",
    "plt.savefig(\"LIGO_2_post_missing_res_errors.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'text.usetex': True,'font.family': 'serif', 'font.serif': ['Palatino'],'font.size':14})\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# mpl.rcParams[‘axes.formatter.useoffset’] = False\n",
    "CORNER_KWARGS = dict(\n",
    "    smooth=0.99, # smooths out contours.\n",
    "    plot_datapoints=False, # choose if you want datapoints\n",
    "    label_kwargs=dict(fontsize=18), # font size for labels\n",
    "    show_titles=True, #choose if you want titles on top of densities.\n",
    "    title_kwargs=dict(fontsize=16), # font size for title\n",
    "    plot_density=False,\n",
    "    quantiles=[0.16, 0.84],  # add quantiles to plot densities.\n",
    "    levels=(1 - np.exp(-0.5), 1 - np.exp(-2), 1 - np.exp(-9 / 2.)),\n",
    "    fill_contours=True, #decide if you want to fill the contours\n",
    "    max_n_ticks=3, # set a limit to ticks in the x-y axes.\n",
    "    title_fmt='.4f', # format for high powers (here 10^2 ~ e+02 etc.)\n",
    "    reverse=False  # if you are a madman, reverse the whole contour.\n",
    ")\n",
    "\n",
    "labels =[r\"$\\log \\mathcal{M}^{(1)}_{c}$\", r\"$\\eta^{(1)}$\", r\"$\\beta^{(1)}$\",\n",
    "          r\"$\\log \\mathcal{M}^{(2)}_{c}$\", r\"$\\eta^{(2)}$\", r\"$\\beta^{(2)}$\"]\n",
    "true_vals = [np.log(M_chirp_1),eta_1,beta_1,\n",
    "             np.log(M_chirp_2),eta_2,beta_2]\n",
    "\n",
    "# fig = corner.corner(samples, bins=30,labels=labels,\n",
    "#                     truths=true_vals, \n",
    "#                     truth_color=\"red\",\n",
    "#                     color=\"black\",**CORNER_KWARGS)\n",
    "\n",
    "fig = corner.corner(samples, bins=30,labels=labels,\n",
    "                    truths=true_vals, \n",
    "                    truth_color=\"red\",\n",
    "                    color=\"black\",**CORNER_KWARGS)\n",
    "red_patch = mpatches.Patch(color=\"red\", label=\"True values\")\n",
    "\n",
    "axes = np.array(fig.axes).reshape((6,6))\n",
    "\n",
    "for i in range(6):\n",
    "    ax = axes[i, i]\n",
    "    ax.axvline(true_vals[i], color=\"red\",linestyle = \"--\",label = 'True Values')\n",
    "    ax.axvline(true_vals[i] + biases_pred_unresolved_total[i] , color=\"orange\",label = 'Predicted Bias')\n",
    "    \n",
    "for yi in range(6):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.axvline(true_vals[xi] + biases_pred_unresolved_total[xi] , color=\"orange\")\n",
    "        ax.axhline(true_vals[yi] + biases_pred_unresolved_total[yi] , color=\"orange\")\n",
    "        ax.plot(true_vals[xi] + biases_pred_unresolved_total[xi] , true_vals[yi] + biases_pred_unresolved_total[yi],\n",
    "                color=\"orange\",marker='s')\n",
    "        ax.axhline(true_vals[yi], color=\"red\")\n",
    "        ax.axvline(true_vals[xi],color= \"red\")\n",
    "\n",
    "for ax in figure.get_axes():\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "        \n",
    "plt.legend(fontsize = 30,bbox_to_anchor=(-2., 5),\n",
    "           loc=\"upper left\")\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('/Users/Ollie/Documents/GitHub_Repositories/population-systematics/Codes/OB/GW_Sources/TaylorF2_Examples/LIGO_case/plots')\n",
    "plt.savefig(\"LIGO_Corner_imp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
